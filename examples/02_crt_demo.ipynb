{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6db2385b",
   "metadata": {},
   "source": [
    "# 02 · CRT Demo (LV/RV endocardium → Trees → Scenarios → Exports → Viewer)\n",
    "\n",
    "This notebook builds **separate Purkinje trees** on the bundled CRT demo meshes:\n",
    "- `data/crtdemo/crtdemo_LVendo_heart_cut.obj`\n",
    "- `data/crtdemo/crtdemo_RVendo_heart_cut.obj`\n",
    "\n",
    "Then it runs a few **pacing scenarios** (baseline, RV-only, BiV with VV-delay), maps activation back to each **surface**, and exports everything for ParaView. The final cell renders an **inline Plotly** 3D view that reliably works in Colab.\n",
    "\n",
    "**Outputs** (under `output/examples/02_crt_demo/`):\n",
    "- LV/RV trees (`*_tree_AT.vtu`) and PMJs (`*_pmj.vtu`)\n",
    "- Merged BiV tree per scenario (`biv_tree_AT_<scenario>.vtu`)\n",
    "- Surface activation for LV/RV per scenario (`*_surface_AT_<scenario>.vtp`)\n",
    "- Parameter snapshots (`params_lv.json`, `params_rv.json`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82dced4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q --upgrade pip purkinje-uv plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097bda67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "from purkinje_uv import FractalTreeParameters, FractalTree, PurkinjeTree\n",
    "import pyvista as pv  # IO + mesh ops\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Repro + knobs\n",
    "SEED = int(os.getenv(\"EXAMPLES_SEED\", \"1234\"))\n",
    "LITE = bool(int(os.getenv(\"EXAMPLES_LITE\", \"1\")))          # fast by default\n",
    "VV_DELAY_MS = int(os.getenv(\"CRT_VV_DELAY_MS\", \"0\"))       # BiV LV delay vs RV (ms); try -40, 0, +40 later\n",
    "\n",
    "# Locations\n",
    "DATA_DIR = Path(\"data\") / \"crtdemo\"\n",
    "OUT_DIR = Path(\"output\") / \"examples\" / \"02_crt_demo\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "np.random.seed(SEED)\n",
    "print(f\"SEED={SEED}  LITE={LITE}  VV_DELAY_MS={VV_DELAY_MS}\")\n",
    "print(\"DATA_DIR:\", DATA_DIR)\n",
    "print(\"OUT_DIR:\", OUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2b0170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure demo OBJ files exist (download from repo if missing)\n",
    "import urllib.request\n",
    "\n",
    "LV_OBJ = DATA_DIR / \"crtdemo_LVendo_heart_cut.obj\"\n",
    "RV_OBJ = DATA_DIR / \"crtdemo_RVendo_heart_cut.obj\"\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def _try_fetch(url: str, dst: Path):\n",
    "    try:\n",
    "        print(\"Downloading:\", url)\n",
    "        with urllib.request.urlopen(url, timeout=30) as r, open(dst, \"wb\") as f:\n",
    "            f.write(r.read())\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(\"  failed:\", e)\n",
    "        return False\n",
    "\n",
    "if not LV_OBJ.exists():\n",
    "    for base in [\n",
    "        \"https://raw.githubusercontent.com/ricardogr07/purkinje-uv/main/data/crtdemo/\",\n",
    "        \"https://raw.githubusercontent.com/ricardogr07/purkinje-uv/master/data/crtdemo/\",\n",
    "        \"https://raw.githubusercontent.com/ricardogr07/purkinje-uv/dev/data/crtdemo/\",\n",
    "    ]:\n",
    "        if _try_fetch(base + LV_OBJ.name, LV_OBJ):\n",
    "            break\n",
    "\n",
    "if not RV_OBJ.exists():\n",
    "    for base in [\n",
    "        \"https://raw.githubusercontent.com/ricardogr07/purkinje-uv/main/data/crtdemo/\",\n",
    "        \"https://raw.githubusercontent.com/ricardogr07/purkinje-uv/master/data/crtdemo/\",\n",
    "        \"https://raw.githubusercontent.com/ricardogr07/purkinje-uv/dev/data/crtdemo/\",\n",
    "    ]:\n",
    "        if _try_fetch(base + RV_OBJ.name, RV_OBJ):\n",
    "            break\n",
    "\n",
    "assert LV_OBJ.exists(), f\"Missing LV OBJ: {LV_OBJ}\"\n",
    "assert RV_OBJ.exists(), f\"Missing RV OBJ: {RV_OBJ}\"\n",
    "print(\"LV_OBJ:\", LV_OBJ)\n",
    "print(\"RV_OBJ:\", RV_OBJ)\n",
    "\n",
    "# Load with PyVista and verify they're open surfaces\n",
    "def load_surface(path: Path) -> pv.PolyData:\n",
    "    mesh = pv.read(str(path))\n",
    "    if not isinstance(mesh, pv.PolyData):\n",
    "        mesh = mesh.extract_geometry()\n",
    "    mesh = mesh.clean().triangulate()\n",
    "    return mesh\n",
    "\n",
    "surf_lv = load_surface(LV_OBJ)\n",
    "surf_rv = load_surface(RV_OBJ)\n",
    "\n",
    "def is_open_surface(pd: pv.PolyData) -> bool:\n",
    "    edges = pd.extract_feature_edges(boundary_edges=True, feature_edges=False,\n",
    "                                     manifold_edges=False, non_manifold_edges=True)\n",
    "    return edges.n_cells > 0\n",
    "\n",
    "print(f\"LV: points={surf_lv.n_points} faces={surf_lv.n_cells} open={is_open_surface(surf_lv)}\")\n",
    "print(f\"RV: points={surf_rv.n_points} faces={surf_rv.n_cells} open={is_open_surface(surf_rv)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81edd88e",
   "metadata": {},
   "source": [
    "## Seeding & Parameters\n",
    "\n",
    "We auto-pick seeds per chamber:\n",
    "- **Root (`init_node_id`)**: vertex nearest to the **boundary center** (mean of boundary-edge points).\n",
    "- **Direction (`second_node_id`)**: vertex **farthest** from the root (good initial heading).\n",
    "\n",
    "Two parameter presets are provided (LITE vs FULL). You can tweak them later to change coverage or density."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d285a100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Utilities ----------\n",
    "def boundary_center(pd: pv.PolyData) -> np.ndarray:\n",
    "    be = pd.extract_feature_edges(boundary_edges=True, feature_edges=False,\n",
    "                                  manifold_edges=False, non_manifold_edges=True)\n",
    "    if be.n_points == 0:\n",
    "        return pd.points.mean(0)\n",
    "    return be.points.mean(0)\n",
    "\n",
    "def auto_seeds(pd: pv.PolyData):\n",
    "    bc = boundary_center(pd)\n",
    "    pts = pd.points\n",
    "    root = int(np.argmin(np.linalg.norm(pts - bc, axis=1)))\n",
    "    direction = int(np.argmax(np.linalg.norm(pts - pts[root], axis=1)))\n",
    "    return root, direction\n",
    "\n",
    "def params_preset(meshfile: str, init_id: int, second_id: int, chamber: str = \"LV\"):\n",
    "    # LITE defaults keep runtime modest; FULL is heavier coverage\n",
    "    if LITE:\n",
    "        lseg = 0.01\n",
    "        if chamber.upper() == \"LV\":\n",
    "            preset = dict(N_it=9, init_length=0.34, length=0.18, branch_angle=0.24, w=0.09,\n",
    "                          fascicles_angles=[-0.6, -0.2, 0.2, 0.6],\n",
    "                          fascicles_length=[0.20, 0.30, 0.30, 0.20])\n",
    "        else:  # RV\n",
    "            preset = dict(N_it=8, init_length=0.32, length=0.16, branch_angle=0.22, w=0.09,\n",
    "                          fascicles_angles=[-0.5, 0.5],\n",
    "                          fascicles_length=[0.25, 0.25])\n",
    "    else:\n",
    "        lseg = 0.008\n",
    "        if chamber.upper() == \"LV\":\n",
    "            preset = dict(N_it=11, init_length=0.36, length=0.20, branch_angle=0.26, w=0.08,\n",
    "                          fascicles_angles=[-0.7, -0.35, 0.0, 0.35, 0.7],\n",
    "                          fascicles_length=[0.25, 0.35, 0.40, 0.35, 0.25])\n",
    "        else:\n",
    "            preset = dict(N_it=10, init_length=0.34, length=0.18, branch_angle=0.24, w=0.08,\n",
    "                          fascicles_angles=[-0.6, 0.0, 0.6],\n",
    "                          fascicles_length=[0.25, 0.30, 0.25])\n",
    "\n",
    "    return FractalTreeParameters(\n",
    "        meshfile=meshfile,\n",
    "        l_segment=lseg,\n",
    "        init_length=preset[\"init_length\"],\n",
    "        length=preset[\"length\"],\n",
    "        branch_angle=preset[\"branch_angle\"],\n",
    "        w=preset[\"w\"],\n",
    "        init_node_id=init_id,\n",
    "        second_node_id=second_id,\n",
    "        N_it=preset[\"N_it\"],\n",
    "        fascicles_angles=preset[\"fascicles_angles\"],\n",
    "        fascicles_length=[x * lseg for x in preset[\"fascicles_length\"]],\n",
    "    )\n",
    "\n",
    "def grow_tree(params: FractalTreeParameters):\n",
    "    ft = FractalTree(params=params)\n",
    "    ft.grow_tree()\n",
    "    return ft\n",
    "\n",
    "def to_arrays(ft: FractalTree):\n",
    "    nodes = np.asarray(ft.nodes_xyz, dtype=float)\n",
    "    edges = np.asarray(ft.connectivity, dtype=int)\n",
    "    pmj   = np.asarray(ft.end_nodes, dtype=int)\n",
    "    return nodes, edges, pmj\n",
    "\n",
    "def merge_trees(nodes_a, edges_a, pmj_a, nodes_b, edges_b, pmj_b):\n",
    "    nA = nodes_a.shape[0]\n",
    "    nodes = np.vstack([nodes_a, nodes_b])\n",
    "    edges = np.vstack([edges_a, edges_b + nA])\n",
    "    pmj   = np.concatenate([pmj_a, pmj_b + nA])\n",
    "    return nodes, edges, pmj\n",
    "\n",
    "def build_P(nodes, edges, pmj) -> PurkinjeTree:\n",
    "    return PurkinjeTree(nodes=np.asarray(nodes, dtype=float),\n",
    "                        connectivity=np.asarray(edges, dtype=int),\n",
    "                        end_nodes=np.asarray(pmj, dtype=int))\n",
    "\n",
    "def solve_activation(P: PurkinjeTree, sources):\n",
    "    \"\"\"sources: list of (node_index, start_time_ms)\"\"\"\n",
    "    x0 = np.array([s[0] for s in sources], dtype=int)\n",
    "    x0_vals = np.array([float(s[1]) for s in sources], dtype=float)\n",
    "    return P.activate_fim(x0=x0, x0_vals=x0_vals, return_only_pmj=False)\n",
    "\n",
    "def nearest_map_activation(surface: pv.PolyData, nodes_xyz: np.ndarray, AT: np.ndarray, chunk=2000):\n",
    "    pts = surface.points\n",
    "    out = np.empty(pts.shape[0], dtype=float)\n",
    "    n = pts.shape[0]\n",
    "    for i in range(0, n, chunk):\n",
    "        j = min(i + chunk, n)\n",
    "        batch = pts[i:j]\n",
    "        # (batch, 1, 3) - (1, nodes, 3) -> (batch, nodes, 3)\n",
    "        d2 = np.sum((batch[:, None, :] - nodes_xyz[None, :, :]) ** 2, axis=2)\n",
    "        idx = np.argmin(d2, axis=1)\n",
    "        out[i:j] = AT[idx]\n",
    "    surf_copy = surface.copy(deep=True)\n",
    "    surf_copy.point_data.clear()\n",
    "    surf_copy.point_data[\"AT\"] = out\n",
    "    return surf_copy\n",
    "\n",
    "def save_surface_vtp(surf: pv.PolyData, path: Path):\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    surf.save(str(path))\n",
    "# --------------------------------------\n",
    "\n",
    "# Auto-pick seeds\n",
    "init_lv, second_lv = auto_seeds(surf_lv)\n",
    "init_rv, second_rv = auto_seeds(surf_rv)\n",
    "print(\"Seeds (LV):\", init_lv, second_lv)\n",
    "print(\"Seeds (RV):\", init_rv, second_rv)\n",
    "\n",
    "# Build params + snapshots\n",
    "params_lv = params_preset(str(LV_OBJ), init_lv, second_lv, chamber=\"LV\")\n",
    "params_rv = params_preset(str(RV_OBJ), init_rv, second_rv, chamber=\"RV\")\n",
    "\n",
    "(params_lv.to_json_file(OUT_DIR / \"params_lv.json\"), params_rv.to_json_file(OUT_DIR / \"params_rv.json\"))\n",
    "print(\"Saved params:\", OUT_DIR / \"params_lv.json\", \"|\", OUT_DIR / \"params_rv.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f456b030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grow LV & RV\n",
    "ft_lv = grow_tree(params_lv)\n",
    "ft_rv = grow_tree(params_rv)\n",
    "\n",
    "nodes_lv, edges_lv, pmj_lv = to_arrays(ft_lv)\n",
    "nodes_rv, edges_rv, pmj_rv = to_arrays(ft_rv)\n",
    "\n",
    "print(f\"LV: nodes={nodes_lv.shape[0]} edges={edges_lv.shape[0]} pmj={pmj_lv.shape[0]}\")\n",
    "print(f\"RV: nodes={nodes_rv.shape[0]} edges={edges_rv.shape[0]} pmj={pmj_rv.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005186fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "P_lv = build_P(nodes_lv, edges_lv, pmj_lv)\n",
    "P_rv = build_P(nodes_rv, edges_rv, pmj_rv)\n",
    "\n",
    "# quick baseline activation per chamber (root @ 0ms) — mainly as a sanity check\n",
    "AT_lv_baseline = solve_activation(P_lv, sources=[(0, 0.0)])\n",
    "AT_rv_baseline = solve_activation(P_rv, sources=[(0, 0.0)])\n",
    "print(\"Baseline sanity — LV AT(min/max):\", float(AT_lv_baseline.min()), float(AT_lv_baseline.max()))\n",
    "print(\"Baseline sanity — RV AT(min/max):\", float(AT_rv_baseline.min()), float(AT_rv_baseline.max()))\n",
    "\n",
    "# Export chamber trees + pmj\n",
    "lv_tree_path = OUT_DIR / \"lv_tree_AT.vtu\"\n",
    "rv_tree_path = OUT_DIR / \"rv_tree_AT.vtu\"\n",
    "lv_pmj_path  = OUT_DIR / \"lv_pmj.vtu\"\n",
    "rv_pmj_path  = OUT_DIR / \"rv_pmj.vtu\"\n",
    "\n",
    "P_lv.save(str(lv_tree_path)); P_lv.save_pmjs(str(lv_pmj_path))\n",
    "P_rv.save(str(rv_tree_path)); P_rv.save_pmjs(str(rv_pmj_path))\n",
    "\n",
    "print(\"Wrote:\")\n",
    "print(\" -\", lv_tree_path)\n",
    "print(\" -\", rv_tree_path)\n",
    "print(\" -\", lv_pmj_path)\n",
    "print(\" -\", rv_pmj_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67688ac6",
   "metadata": {},
   "source": [
    "## Merge Trees & Target Pacing Sites\n",
    "\n",
    "We merge LV+RV into a single **disconnected** tree for BiV scenarios (FIM supports multiple sources).  \n",
    "We then pick:\n",
    "- **RV apex**: extreme along the first principal component (PC1) of the RV surface.\n",
    "- **LV lateral**: extreme along the second principal component (PC2) of the LV surface.\n",
    "\n",
    "Finally, we locate the **nearest tree node** to each target point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1dc76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge LV + RV into a single tree (no connecting edge)\n",
    "nodes_biv, edges_biv, pmj_biv = merge_trees(nodes_lv, edges_lv, pmj_lv, nodes_rv, edges_rv, pmj_rv)\n",
    "P_biv = build_P(nodes_biv, edges_biv, pmj_biv)\n",
    "\n",
    "# Helpers for PCA-based targets\n",
    "def pca_axes(pts: np.ndarray):\n",
    "    X = pts - pts.mean(0, keepdims=True)\n",
    "    U, S, Vt = np.linalg.svd(X, full_matrices=False)\n",
    "    # rows of Vt are principal axes\n",
    "    return Vt\n",
    "\n",
    "def extreme_point_along(pc: np.ndarray, pts: np.ndarray, which: str = \"min\"):\n",
    "    proj = pts @ pc\n",
    "    return pts[np.argmin(proj) if which == \"min\" else np.argmax(proj)]\n",
    "\n",
    "def nearest_node_idx(nodes: np.ndarray, point: np.ndarray) -> int:\n",
    "    return int(np.argmin(np.sum((nodes - point[None, :])**2, axis=1)))\n",
    "\n",
    "# RV apex (along PC1)\n",
    "Vt_rv = pca_axes(surf_rv.points)\n",
    "rv_apex_pt = extreme_point_along(Vt_rv[0], surf_rv.points, which=\"min\")\n",
    "rv_apex_idx_rv = nearest_node_idx(nodes_rv, rv_apex_pt)       # index in RV tree\n",
    "\n",
    "# LV lateral (along PC2)\n",
    "Vt_lv = pca_axes(surf_lv.points)\n",
    "lv_lat_pt = extreme_point_along(Vt_lv[1], surf_lv.points, which=\"max\")\n",
    "lv_lat_idx_lv = nearest_node_idx(nodes_lv, lv_lat_pt)         # index in LV tree\n",
    "\n",
    "# Convert LV/RV indices to merged space\n",
    "offset_rv = nodes_lv.shape[0]\n",
    "lv_lat_idx_biv = lv_lat_idx_lv                                # LV stays as-is\n",
    "rv_apex_idx_biv = rv_apex_idx_rv + offset_rv                  # RV shifted by LV size\n",
    "\n",
    "print(\"Lead targets → RV apex (rv idx):\", rv_apex_idx_rv, \" | LV lateral (lv idx):\", lv_lat_idx_lv)\n",
    "print(\"Merged indices  → RV apex:\", rv_apex_idx_biv, \" | LV lateral:\", lv_lat_idx_biv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9862ea21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define scenarios\n",
    "# - baseline: stimulate the root (node 0) of each chamber at t=0 ms\n",
    "# - rv_only: RV apex at t=0\n",
    "# - biv: RV apex at t=0 and LV lateral at t=VV_DELAY_MS\n",
    "scenarios = {}\n",
    "\n",
    "# Baseline: two independent stim in merged tree (LV root @0, RV root+offset @0)\n",
    "src_baseline = [(0, 0.0), (nodes_lv.shape[0], 0.0)]\n",
    "scenarios[\"baseline\"] = solve_activation(P_biv, src_baseline)\n",
    "\n",
    "# RV-only\n",
    "src_rv = [(rv_apex_idx_biv, 0.0)]\n",
    "scenarios[\"rv_only\"] = solve_activation(P_biv, src_rv)\n",
    "\n",
    "# BiV\n",
    "src_biv = [(rv_apex_idx_biv, 0.0), (lv_lat_idx_biv, float(VV_DELAY_MS)/1000.0)]  # adjust units if needed\n",
    "scenarios[\"biv\"] = solve_activation(P_biv, src_biv)\n",
    "\n",
    "for name, AT in scenarios.items():\n",
    "    print(f\"{name}: AT min/max = {float(AT.min()):.4f} / {float(AT.max()):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d944ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map activations back to each surface and export\n",
    "def export_surface_AT(name: str, AT_biv: np.ndarray):\n",
    "    # Split node arrays back into LV and RV portions\n",
    "    n_lv = nodes_lv.shape[0]\n",
    "    AT_lv = AT_biv[:n_lv]\n",
    "    AT_rv = AT_biv[n_lv:]\n",
    "    # Map to surfaces (nearest neighbor)\n",
    "    lv_at_surf = nearest_map_activation(surf_lv, nodes_lv, AT_lv)\n",
    "    rv_at_surf = nearest_map_activation(surf_rv, nodes_rv, AT_rv)\n",
    "    # Save\n",
    "    lv_path = OUT_DIR / f\"lv_surface_AT_{name}.vtp\"\n",
    "    rv_path = OUT_DIR / f\"rv_surface_AT_{name}.vtp\"\n",
    "    save_surface_vtp(lv_at_surf, lv_path)\n",
    "    save_surface_vtp(rv_at_surf, rv_path)\n",
    "    print(\"Saved surfaces:\", lv_path.name, \"|\", rv_path.name)\n",
    "\n",
    "for scen, AT in scenarios.items():\n",
    "    export_surface_AT(scen, AT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d70d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save merged tree per scenario (useful for ParaView)\n",
    "def save_tree_with_AT(nodes, edges, AT, name: str):\n",
    "    Ptmp = build_P(nodes, edges, pmj_biv)\n",
    "    path = OUT_DIR / f\"biv_tree_AT_{name}.vtu\"\n",
    "    Ptmp.save(str(path))\n",
    "    print(\"Saved:\", path.name)\n",
    "\n",
    "for scen, AT in scenarios.items():\n",
    "    save_tree_with_AT(nodes_biv, edges_biv, AT, scen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d871299f",
   "metadata": {},
   "source": [
    "## Plotly Viewer (LV/RV surfaces + tree + PMJs)\n",
    "\n",
    "Interactive and reliable in Colab. Use the dropdown to switch scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767fbec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Plotly figure with a dropdown to switch scenarios\n",
    "def mesh3d_from_surface_with_AT(surface: pv.PolyData):\n",
    "    pts = surface.points\n",
    "    faces = surface.faces.reshape(-1, 4)[:, 1:]\n",
    "    at = surface.point_data[\"AT\"] if \"AT\" in surface.point_data else None\n",
    "    trace = go.Mesh3d(\n",
    "        x=pts[:,0], y=pts[:,1], z=pts[:,2],\n",
    "        i=faces[:,0], j=faces[:,1], k=faces[:,2],\n",
    "        name=\"surface\", opacity=0.25, lighting=dict(ambient=0.6, diffuse=0.6),\n",
    "        intensity=at if at is not None else None,\n",
    "        colorscale=\"Viridis\",\n",
    "        showscale=True if at is not None else False,\n",
    "        colorbar=dict(title=\"AT\") if at is not None else None,\n",
    "    )\n",
    "    return trace\n",
    "\n",
    "def line_segments_from_edges(points: np.ndarray, edges: np.ndarray, name=\"tree\", width=3):\n",
    "    xs, ys, zs = [], [], []\n",
    "    for u, v in edges:\n",
    "        xs += [points[u,0], points[v,0], None]\n",
    "        ys += [points[u,1], points[v,1], None]\n",
    "        zs += [points[u,2], points[v,2], None]\n",
    "    return go.Scatter3d(x=xs, y=ys, z=zs, mode=\"lines\", line=dict(width=width), name=name)\n",
    "\n",
    "def scatter_points(points: np.ndarray, name=\"PMJs\", size=4, color=\"crimson\"):\n",
    "    if points.size == 0:\n",
    "        return go.Scatter3d(x=[], y=[], z=[], mode=\"markers\", name=name)\n",
    "    return go.Scatter3d(x=points[:,0], y=points[:,1], z=points[:,2],\n",
    "                        mode=\"markers\", marker=dict(size=size, color=color, symbol=\"square\"),\n",
    "                        name=name)\n",
    "\n",
    "# Precompute PMJ coordinates\n",
    "pmj_coords_lv = nodes_lv[pmj_lv] if pmj_lv.size else np.empty((0,3))\n",
    "pmj_coords_rv = nodes_rv[pmj_rv] if pmj_rv.size else np.empty((0,3))\n",
    "\n",
    "# Prepare surface AT variants for each scenario\n",
    "surfaces_by_scen = {}\n",
    "for scen, AT in scenarios.items():\n",
    "    n_lv = nodes_lv.shape[0]\n",
    "    lv_at = AT[:n_lv]\n",
    "    rv_at = AT[n_lv:]\n",
    "    lv_surf = nearest_map_activation(surf_lv, nodes_lv, lv_at)\n",
    "    rv_surf = nearest_map_activation(surf_rv, nodes_rv, rv_at)\n",
    "    surfaces_by_scen[scen] = (lv_surf, rv_surf)\n",
    "\n",
    "scen_list = list(surfaces_by_scen.keys())\n",
    "\n",
    "# Construct traces per scenario\n",
    "traces_all = []\n",
    "vis_masks = []\n",
    "for scen in scen_list:\n",
    "    lv_surf, rv_surf = surfaces_by_scen[scen]\n",
    "    # Surfaces\n",
    "    t_lv = mesh3d_from_surface_with_AT(lv_surf); traces_all.append(t_lv)\n",
    "    t_rv = mesh3d_from_surface_with_AT(rv_surf); traces_all.append(t_rv)\n",
    "    # Trees (same geometry for all scenarios)\n",
    "    t_tree_lv = line_segments_from_edges(nodes_lv, edges_lv, name=\"LV tree\"); traces_all.append(t_tree_lv)\n",
    "    t_tree_rv = line_segments_from_edges(nodes_rv, edges_rv, name=\"RV tree\"); traces_all.append(t_tree_rv)\n",
    "    # PMJs\n",
    "    t_pmj_lv = scatter_points(pmj_coords_lv, name=\"LV PMJs\"); traces_all.append(t_pmj_lv)\n",
    "    t_pmj_rv = scatter_points(pmj_coords_rv, name=\"RV PMJs\"); traces_all.append(t_pmj_rv)\n",
    "    # visibility mask for this scenario (True for these 6 traces; False for others)\n",
    "    mask = [False]* (6*len(scen_list))\n",
    "    start = scen_list.index(scen)*6\n",
    "    for k in range(start, start+6):\n",
    "        mask[k] = True\n",
    "    vis_masks.append(mask)\n",
    "\n",
    "fig = go.Figure(data=traces_all)\n",
    "# Initial visibility: first scenario\n",
    "if vis_masks:\n",
    "    for trace, show in zip(fig.data, vis_masks[0]):\n",
    "        trace.visible = show\n",
    "\n",
    "# Dropdown buttons\n",
    "buttons = []\n",
    "for i, scen in enumerate(scen_list):\n",
    "    buttons.append(dict(method=\"update\",\n",
    "                        label=scen,\n",
    "                        args=[{\"visible\": vis_masks[i]}],\n",
    "                        args2=[{\"visible\": vis_masks[0]}]))\n",
    "\n",
    "fig.update_layout(\n",
    "    updatemenus=[dict(type=\"dropdown\", x=0.01, y=0.99, buttons=buttons, showactive=True)],\n",
    "    scene=dict(aspectmode=\"data\"),\n",
    "    margin=dict(l=0, r=0, t=30, b=0),\n",
    "    title=f\"CRT Demo — scenarios: {', '.join(scen_list)}\"\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
